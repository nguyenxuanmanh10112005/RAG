import streamlit as st
import faiss
import json
import numpy as np
import subprocess
import re
import unicodedata
from sentence_transformers import SentenceTransformer

# ==========================
# âš™ï¸ 1. Cáº¥u hÃ¬nh Ollama
# ==========================
OLLAMA_PATH = r"C:\Users\ADMIN\AppData\Local\Programs\Ollama\ollama.exe"
MODEL_NAME = "qwen2:0.5b"

# ==========================
# âš™ï¸ 2. Load mÃ´ hÃ¬nh embedding & dá»¯ liá»‡u FAISS
# ==========================
@st.cache_resource
def load_model():
    return SentenceTransformer("intfloat/multilingual-e5-small")

@st.cache_resource
def load_data():
    index = faiss.read_index("storage/law_index.faiss")
    with open("storage/law_metadata.json", "r", encoding="utf-8") as f:
        metadata = json.load(f)
    # LÆ°u danh sÃ¡ch sá»‘ Ä‘iá»u Ä‘á»ƒ kiá»ƒm tra
    existing_articles = [int(re.findall(r"\d+", m['content'])[0]) for m in metadata]
    return index, metadata, existing_articles

model = load_model()
index, metadata, existing_articles = load_data()

# ==========================
# ğŸ§¹ 3. Chuáº©n hÃ³a vÄƒn báº£n
# ==========================
def normalize_text(text: str) -> str:
    text = text.lower()
    text = unicodedata.normalize('NFC', text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# ==========================
# ğŸ” 4. FAISS retrieval
# ==========================
def retrieve_context(query, top_k=1, threshold=0.25):
    query_norm = normalize_text(query)
    q_emb = model.encode([query_norm], convert_to_numpy=True)
    D, I = index.search(q_emb, top_k)

    sims = [1 / (1 + d) for d in D[0]]
    contexts = []
    for idx, sim in zip(I[0], sims):
        if idx < len(metadata) and sim >= threshold:
            contexts.append(f"[Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {sim:.2f}]\n{metadata[idx]['content']}")

    # Fallback náº¿u khÃ´ng tÃ¬m tháº¥y káº¿t quáº£
    if not contexts and top_k < 6:
        return retrieve_context(query, top_k=6, threshold=0.15)

    return "\n---\n".join(contexts), len(contexts)

# ==========================
# âš–ï¸ 5. Kiá»ƒm tra cÃ¢u há»i vá» sá»‘ Ä‘iá»u
# ==========================
def check_article_exists(query):
    """Náº¿u ngÆ°á»i dÃ¹ng há»i Äiá»u X, kiá»ƒm tra X cÃ³ tá»“n táº¡i khÃ´ng"""
    match = re.search(r"Ä‘iá»u\s*(\d+)", query.lower())
    if match:
        number = int(match.group(1))
        if number not in existing_articles:
            return False
    return True

# ==========================
# ğŸ¤– 6. Gá»i Ollama qwen2:0.5b
# ==========================
def generate_answer(context, query):
    prompt = f"""
Báº¡n lÃ  trá»£ lÃ½ phÃ¡p lÃ½ am hiá»ƒu Bá»™ luáº­t Lao Ä‘á»™ng Viá»‡t Nam.

CÃ¡c Ä‘iá»u luáº­t liÃªn quan:
{context}

CÃ¢u há»i: {query}

YÃªu cáº§u:
- Tráº£ lá»i ngáº¯n gá»n (â‰¤120 tá»«), dá»… hiá»ƒu, báº±ng tiáº¿ng Viá»‡t.
- Chá»‰ dá»±a trÃªn ná»™i dung Ä‘iá»u luáº­t, khÃ´ng bá»‹a Ä‘áº·t.
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin, tráº£ lá»i:
  "KhÃ´ng cÃ³ thÃ´ng tin trong Bá»™ luáº­t Lao Ä‘á»™ng hiá»‡n hÃ nh."
"""
    try:
        result = subprocess.run(
            [OLLAMA_PATH, "run", MODEL_NAME],
            input=prompt,
            text=True,
            encoding="utf-8",
            errors="ignore",
            capture_output=True,
            timeout=180
        )
        if result.returncode != 0:
            return f"âš ï¸ Lá»—i Ollama: {result.stderr.strip() or result.stdout.strip()}"
        return result.stdout.strip() or "âš ï¸ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« mÃ´ hÃ¬nh."
    except Exception as e:
        return f"âš ï¸ Lá»—i khi gá»i Ollama: {e}"

# ==========================
# ğŸŒ 7. Giao diá»‡n Streamlit
# ==========================
st.set_page_config(page_title="Há»i Ä‘Ã¡p Luáº­t Viá»‡t Nam (RAG)", page_icon="âš–ï¸")
st.title("âš–ï¸ Há»† THá»NG Há»I ÄÃP LUáº¬T VIá»†T NAM (RAG)")
st.caption("Dá»±a trÃªn FAISS + mÃ´ hÃ¬nh LLM qwen2:0.5b cháº¡y offline qua Ollama.")

query = st.text_input("ğŸ” Nháº­p cÃ¢u há»i:", placeholder="VÃ­ dá»¥: Äiá»u 1 nÃ³i vá» váº¥n Ä‘á» gÃ¬?")

if query:
    with st.spinner("â³ Äang truy xuáº¥t vÃ  xá»­ lÃ½..."):
        # Kiá»ƒm tra náº¿u ngÆ°á»i dÃ¹ng há»i Äiá»u X khÃ´ng tá»“n táº¡i
        if not check_article_exists(query):
            st.warning("âš–ï¸ KhÃ´ng cÃ³ thÃ´ng tin trong Bá»™ luáº­t Lao Ä‘á»™ng hiá»‡n hÃ nh.")
        else:
            context, found = retrieve_context(query)

            if found == 0:
                st.warning("âš–ï¸ KhÃ´ng tÃ¬m tháº¥y Ä‘iá»u luáº­t liÃªn quan. HÃ£y thá»­ diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i.")
            else:
                st.info(f"ğŸ” ÄÃ£ tÃ¬m tháº¥y {found} Ä‘iá»u luáº­t liÃªn quan.")
                if len(context) > 4000:
                    context = context[:4000]

                answer = generate_answer(context, query)
                st.subheader("ğŸ§  CÃ¢u tráº£ lá»i:")
                st.success(answer)

                with st.expander("ğŸ“œ Xem cÃ¡c Ä‘iá»u luáº­t Ä‘Æ°á»£c sá»­ dá»¥ng"):
                    st.text(context)
