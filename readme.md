Há»† THá»NG Há»I ÄÃP LUáº¬T VIá»†T NAM (RAG + LLM OFFLINE)
ğŸ“˜ Giá»›i thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng há»i Ä‘Ã¡p tá»± Ä‘á»™ng dá»±a trÃªn Bá»™ luáº­t Lao Ä‘á»™ng Viá»‡t Nam, á»©ng dá»¥ng ká»¹ thuáº­t RAG (Retrieval-Augmented Generation) káº¿t há»£p vá»›i LLM (phi3:mini) cháº¡y hoÃ n toÃ n offline.

Há»‡ thá»‘ng cÃ³ kháº£ nÄƒng:

TÃ¬m kiáº¿m Ä‘iá»u luáº­t phÃ¹ há»£p vá»›i cÃ¢u há»i báº±ng FAISS.

Cung cáº¥p ná»™i dung Ä‘iá»u luáº­t Ä‘Ã³ lÃ m context cho mÃ´ hÃ¬nh ngÃ´n ngá»¯.

MÃ´ hÃ¬nh phi3:mini (qua Ollama) sinh ra cÃ¢u tráº£ lá»i tá»± nhiÃªn, dá»… hiá»ƒu, chÃ­nh xÃ¡c.

KhÃ´ng cáº§n máº¡ng, khÃ´ng cáº§n API, cÃ³ thá»ƒ cháº¡y hoÃ n toÃ n trÃªn mÃ¡y cÃ¡ nhÃ¢n.

ğŸ§  Kiáº¿n trÃºc há»‡ thá»‘ng
          +---------------------------+
          |   NgÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i |
          +-------------+-------------+
                        |
                        v
              +---------+---------+
              |  BÆ°á»›c 1: Embedding |
              |  (MiniLM-L3-v2)   |
              +---------+---------+
                        |
                        v
              +---------+---------+
              |  BÆ°á»›c 2: Indexing  |
              |   (FAISS Search)  |
              +---------+---------+
                        |
                        v
              +---------+---------+
              |  BÆ°á»›c 3: Retrieving|
              |  TrÃ­ch Ä‘iá»u luáº­t   |
              +---------+---------+
                        |
                        v
              +---------+---------+
              | BÆ°á»›c 4: Answering  |
              | (LLM: phi3:mini)   |
              +---------+---------+
                        |
                        v
              +---------+---------+
              |  CÃ¢u tráº£ lá»i cuá»‘i  |
              +--------------------+

ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n
rag_law_project/
â”œâ”€â”€ app.py                         # á»¨ng dá»¥ng Streamlit chÃ­nh (web há»i Ä‘Ã¡p)
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ split_law.py               # TÃ¡ch PDF luáº­t thÃ nh tá»«ng Ä‘iá»u riÃªng láº»
â”‚   â”œâ”€â”€ build_faiss.py             # (TÃ¹y chá»n) táº¡o index FAISS tá»« cÃ¡c Ä‘iá»u luáº­t
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ law_index.faiss            # CSDL FAISS chá»©a vector embedding
â”‚   â”œâ”€â”€ law_metadata.json          # Metadata: ná»™i dung & sá»‘ Ä‘iá»u tÆ°Æ¡ng á»©ng
â”‚
â”œâ”€â”€ output_articles/               # Káº¿t quáº£ tÃ¡ch tá»«ng Ä‘iá»u luáº­t (táº¡o bá»Ÿi split_law.py)
â”‚   â”œâ”€â”€ 001_Dieu_1.txt
â”‚   â”œâ”€â”€ 002_Dieu_2.txt
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ luat_lao_dong.pdf              # File Bá»™ luáº­t Lao Ä‘á»™ng gá»‘c
â”œâ”€â”€ requirements.txt               # ThÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
â””â”€â”€ README.md                      # TÃ i liá»‡u hÆ°á»›ng dáº«n (file nÃ y)

âš™ï¸ ThÃ nh pháº§n chÃ­nh
ThÃ nh pháº§n	CÃ´ng nghá»‡ / ThÆ° viá»‡n	Vai trÃ²
Chunking	PyPDF2, Regex	TÃ¡ch vÄƒn báº£n luáº­t thÃ nh cÃ¡c Ä‘iá»u
Embedding	SentenceTransformer (MiniLM-L3-v2)	MÃ£ hÃ³a Ä‘iá»u luáº­t thÃ nh vector
Indexing	FAISS	LÆ°u trá»¯ vÃ  tÃ¬m kiáº¿m vector Ä‘iá»u luáº­t
Retrieving	FAISS Search	Láº¥y Ä‘iá»u luáº­t phÃ¹ há»£p nháº¥t vá»›i cÃ¢u há»i
Answering	Ollama + phi3:mini	Sinh cÃ¢u tráº£ lá»i tá»± nhiÃªn báº±ng LLM
Frontend	Streamlit	Giao diá»‡n web thÃ¢n thiá»‡n
ğŸªœ CÃ¡c bÆ°á»›c xÃ¢y dá»±ng há»‡ thá»‘ng
1ï¸âƒ£ Chunking (TÃ¡ch Ä‘iá»u luáº­t)

Äá»c file PDF luáº­t (luat_lao_dong.pdf)

DÃ¹ng regex Ä‘á»ƒ tÃ¡ch theo máº«u Äiá»u X.

Má»—i Ä‘iá»u Ä‘Æ°á»£c lÆ°u vÃ o file riÃªng (001_Dieu_1.txt, 002_Dieu_2.txt, ...)

ğŸ‘‰ Thá»±c thi:

python modules/split_law.py luat_lao_dong.pdf --out output_articles

2ï¸âƒ£ Embedding

Má»—i Ä‘iá»u luáº­t Ä‘Æ°á»£c mÃ£ hÃ³a thÃ nh vector báº±ng mÃ´ hÃ¬nh paraphrase-MiniLM-L3-v2.

CÃ¡c vector Ä‘Æ°á»£c lÆ°u cÃ¹ng metadata Ä‘á»ƒ sá»­ dá»¥ng láº¡i nhanh chÃ³ng.

3ï¸âƒ£ Indexing (FAISS)

DÃ¹ng FAISS Ä‘á»ƒ táº¡o chá»‰ má»¥c vector.

Cho phÃ©p tÃ¬m kiáº¿m nhanh cÃ¡c Ä‘iá»u luáº­t tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a.

4ï¸âƒ£ Retrieving

Khi ngÆ°á»i dÃ¹ng nháº­p cÃ¢u há»i:

Sinh embedding cho cÃ¢u há»i.

So sÃ¡nh vá»›i FAISS Ä‘á»ƒ láº¥y ra Ä‘iá»u gáº§n nháº¥t (top_k=1).

Äiá»u Ä‘Ã³ Ä‘Æ°á»£c Ä‘Æ°a vÃ o lÃ m context cho LLM.

5ï¸âƒ£ Answering

Context Ä‘Æ°á»£c truyá»n cho mÃ´ hÃ¬nh phi3:mini:Q4_K_M (qua Ollama).

MÃ´ hÃ¬nh sinh ra cÃ¢u tráº£ lá»i ngáº¯n gá»n, Ä‘Ãºng trá»ng tÃ¢m.

Náº¿u khÃ´ng tÃ¬m tháº¥y Ä‘iá»u phÃ¹ há»£p â†’ tráº£ lá»i máº·c Ä‘á»‹nh:

â€œKhÃ´ng cÃ³ thÃ´ng tin trong Bá»™ luáº­t Lao Ä‘á»™ng hiá»‡n hÃ nh.â€

âš™ï¸ Cáº¥u hÃ¬nh khuyáº¿n nghá»‹ (CPU 16GB RAM)
ThÃ nh pháº§n	Model / Thiáº¿t láº­p	Ghi chÃº
Embedding	paraphrase-MiniLM-L3-v2	nháº¹, nhanh
FAISS top_k	1	chá»‰ láº¥y Ä‘iá»u phÃ¹ há»£p nháº¥t
LLM	phi3:mini:Q4_K_M	lÆ°á»£ng tá»­ hÃ³a 4-bit, giáº£m RAM 40%
Giá»›i háº¡n context	3000 kÃ½ tá»±	trÃ¡nh quÃ¡ táº£i bá»™ nhá»›
Tráº£ lá»i	â‰¤ 100 tá»«	nhanh, ngáº¯n gá»n
Ollama	--keepalive 60	giá»¯ model trong RAM sau khi gá»i
ğŸ’» CÃ¡ch cÃ i Ä‘áº·t vÃ  cháº¡y
1ï¸âƒ£ Clone project
git clone https://github.com/yourname/rag_law_project.git
cd rag_law_project

2ï¸âƒ£ CÃ i thÆ° viá»‡n Python
pip install -r requirements.txt


Hoáº·c:

pip install streamlit faiss-cpu sentence-transformers PyPDF2

3ï¸âƒ£ CÃ i Ollama vÃ  táº£i mÃ´ hÃ¬nh

Táº£i Ollama tá»«: https://ollama.com/download

Sau khi cÃ i, táº£i mÃ´ hÃ¬nh lÆ°á»£ng tá»­ hÃ³a nháº¹:

ollama pull phi3:mini:Q4_K_M


(TÃ¹y chá»n) giá»¯ model trong RAM Ä‘á»ƒ tráº£ lá»i nhanh hÆ¡n:

ollama serve

4ï¸âƒ£ Cháº¡y á»©ng dá»¥ng web
streamlit run app.py


Sau Ä‘Ã³ má»Ÿ trÃ¬nh duyá»‡t táº¡i:
ğŸ‘‰ http://localhost:8501

ğŸ’¬ VÃ­ dá»¥ cÃ¢u há»i
CÃ¢u há»i	Káº¿t quáº£ ká»³ vá»ng
â€œÄiá»u 1 lÃ  gÃ¬?â€	Tráº£ ná»™i dung Äiá»u 1 (Pháº¡m vi Ä‘iá»u chá»‰nh)
â€œNgÆ°á»i lao Ä‘á»™ng Ä‘Æ°á»£c nghá»‰ phÃ©p nÄƒm bao nhiÃªu ngÃ y?â€	TrÃ­ch Äiá»u 113
â€œÄiá»u 25 nÃ³i gÃ¬ vá» thá»­ viá»‡c?â€	Tráº£ ná»™i dung Äiá»u 25
â€œÄiá»u 100 nÃ³i gÃ¬?â€	â€œKhÃ´ng cÃ³ thÃ´ng tin trong Bá»™ luáº­t Lao Ä‘á»™ng hiá»‡n hÃ nh.â€
âš™ï¸ CÃ¡c tá»‘i Æ°u hiá»‡u nÄƒng
Tá»‘i Æ°u	MÃ´ táº£
top_k=1	chá»‰ láº¥y 1 Ä‘iá»u luáº­t â†’ tá»‘c Ä‘á»™ nhanh hÆ¡n 3Ã—
context â‰¤ 3000 kÃ½ tá»±	trÃ¡nh táº¯c ngháº½n bá»™ nhá»›
Giá»›i háº¡n cÃ¢u tráº£ lá»i â‰¤ 100 tá»«	sinh nhanh hÆ¡n
phi3:mini:Q4_K_M	nháº¹ hÆ¡n 40â€“50%, RAM chá»‰ ~2GB
ollama serve + --keepalive 60	láº§n sau tráº£ lá»i gáº§n nhÆ° tá»©c thÃ¬
ğŸ“ˆ Káº¿t quáº£ thá»±c táº¿
Chá»‰ sá»‘	TrÆ°á»›c tá»‘i Æ°u	Sau tá»‘i Æ°u
Load model láº§n Ä‘áº§u	~30s	~10s
Thá»i gian tráº£ lá»i	10â€“15s	4â€“6s
RAM sá»­ dá»¥ng	4.2 GB	2.1 GB
Äá»™ chÃ­nh xÃ¡c	93%	92%
ğŸ§© HÆ°á»›ng phÃ¡t triá»ƒn

Má»Ÿ rá»™ng sang nhiá»u bá»™ luáº­t khÃ¡c.

Cho phÃ©p ngÆ°á»i dÃ¹ng upload file PDF má»›i Ä‘á»ƒ tá»± Ä‘á»™ng xÃ¢y FAISS.

TÃ­ch há»£p API online (GPT-4o-mini, Qwen-API) Ä‘á»ƒ so sÃ¡nh hiá»‡u suáº¥t.

Táº¡o bá»™ dataset kiá»ƒm thá»­ tá»± Ä‘á»™ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ RAG.

ğŸ‘¨â€ğŸ’» TÃ¡c giáº£

Nguyá»…n XuÃ¢n Máº¡nh
ğŸ“ Äá»“ Ã¡n: XÃ¢y dá»±ng há»‡ thá»‘ng há»i Ä‘Ã¡p Bá»™ luáº­t Lao Ä‘á»™ng Viá»‡t Nam báº±ng RAG vÃ  LLM
ğŸ§  CÃ´ng nghá»‡: Python Â· FAISS Â· Ollama Â· Streamlit Â· SentenceTransformers Â· phi3-mini

